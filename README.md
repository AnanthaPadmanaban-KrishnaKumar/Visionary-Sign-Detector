# visionary_sign_detector

## Data Source

For this project, we utilized the [Cityscapes Dataset](https://www.cityscapes-dataset.com), an expansive and detailed collection specifically designed for the semantic understanding of urban street scenes, with a particular focus on applications in autonomous driving. This dataset includes a diverse array of stereo video sequences captured in the streets of 50 different cities. What sets the Cityscapes Dataset apart is its exceptional quality of pixel-level annotations provided for 5,000 frames, along with coarser annotations for an additional 20,000 frames. These annotations cover a broad spectrum of urban environments, recorded under various conditions such as different seasons, weather, and times of day.

As a benchmark in the computer vision community, the Cityscapes Dataset is instrumental for tasks like semantic segmentation, object detection, and instance-level segmentation. The dataset offers comprehensive annotations that categorize individual pixels into classes such as roads, sidewalks, cars, pedestrians, and more. This level of detail makes the Cityscapes Dataset an indispensable resource for training and evaluating computer vision models, particularly those designed to navigate and understand complex urban landscapes.

